# Livora Enterprise Intelligence — Technical Build Guide (A → Z)

**Purpose:**
This is a complete, start‑to‑end technical guide your engineering team can follow to build the Livora Enterprise Intelligence system (the unified backend: Analytics + CRM + Automation + Integrations). It assumes the frontend (web & mobile) is already available and focuses purely on the backend, infra, data flows, integrations, and operational practices. This document is prescriptive — developers/architects can copy, implement, and extend directly.

---

## 1. High‑level system scope
The Livora Engine provides:
- Real‑time event ingestion from web/mobile/desktop.
- Operational stores for sessions, carts, orders (fast reads/writes).
- Relational CRM (contacts, deals, activities) for business users.
- Analytics data lake + warehouse for funnel, cohort, LTV, A/B testing.
- Campaign & automation engine (WhatsApp, Email, SMS, Push).
- AI/ML layer for predictions and recommendations.
- Read APIs & embedded dashboards for the CRM desktop app.

**Not included in this document:** frontend UI implementation (except API contracts), client-specific branding, and pricing decisions.

---

## 2. Architectural overview (logical layers)
1. **Ingestion (Edge)** — SDKs / Frontend → API Gateway
2. **Stream Processing** — Kinesis / Pub/Sub → Enrich & Sessionize
3. **Operational Stores** — DynamoDB (NoSQL) + Aurora PostgreSQL (CRM)
4. **Data Lake & Warehouse** — S3 / GCS → Glue / Dataflow → Redshift / BigQuery
5. **Analytics & BI** — materialized aggregates, QuickSight / Metabase / Superset
6. **Automation & Campaigns** — Step Functions / Workflow Orchestrator + Campaign Engine
7. **AI/ML** — feature store, batch/online models, training pipelines
8. **API Layer & Control Plane** — REST/GraphQL APIs, Read APIs for CRM desktop
9. **Infra & Ops** — IaC (CDK/Terraform), CI/CD, monitoring, backups, IAM

Diagram (text):
```
[Clients] -> API Gateway -> Ingress Lambda -> Kinesis -> Enrichment ->
 -> DynamoDB (ops) and Firehose -> S3 -> Glue -> Redshift
CRM API (Aurora) <-> Order Service -> emits events -> EventBridge -> Kinesis
Automation Engine reads Enriched Stream -> triggers Campaigns via Twilio/SES
AI Mix: Feature Store (Redis/Dynamo) <-> Models (SageMaker) -> Predictions -> APIs
``` 

---

## 3. Core design principles
- **Event‑first**: All user actions are events; raw events persist to S3 immediately.
- **Separation of concerns**: Operational store for realtime features; data lake/warehouse for analytics.
- **Idempotency**: Every event includes `event_id` to dedupe in processing.
- **Schema evolution**: Use Glue Schema Registry / Avro/Protobuf for versioning.
- **Client data ownership**: Deploy to client cloud accounts; data remains under client control.
- **Config‑driven modules**: Feature flags & JSON configuration to enable/disable modules per client.
- **Security by default**: Least privilege IAM, KMS encryption, RBAC at API level.

---

## 4. Event model (canonical)
All events follow the canonical schema. This is mandatory: SDKs and backend must agree.

```json
{
  "event_id": "uuid-v4",
  "timestamp": "ISO-8601",
  "client_id": "client_xyz",
  "user_id": "auth|1234", // optional if logged in
  "anon_id": "device|abcd",
  "session_id": "sess|abcdef",
  "event_type": "product_view",
  "props": { /* event specific */ },
  "context": { "ip": "", "ua": "", "locale": "" }
}
```

- **Storage**: write raw JSON to S3 partitioned by `dt=YYYY-MM-DD/hour` using Firehose. 
- **Validation**: API layer rejects invalid events (missing event_id/timestamp).

---

## 5. Ingestion & Stream Processing
**Components:** API Gateway (REST/GraphQL), Ingress Lambda (auth, basic validation), Kinesis Data Streams / Pub/Sub.

**Responsibilities:**
- Throttle and authenticate incoming traffic.
- Enrich events with basic data (geo from IP, timestamp normalisation).
- Publish to primary stream.
- Firehose delivers compressed Parquet to S3 for long term storage.

**Consumers:**
- **Realtime Lambda/Flink** for enrichment, dedupe, sessionization, and writes to DynamoDB operational tables.
- **ETL jobs (Glue / Dataflow)** for batch transforms into warehouse.

**Best practices:**
- Use batching on SDKs to reduce calls.
- Use provisioned throughput with autoscaling or on‑demand mode for DynamoDB.
- Monitor iterator age and retry policies for Kinesis.

---

## 6. Operational Stores (DynamoDB + Aurora)
**DynamoDB (single‑table pattern recommended)**
- Purpose: fast reads/writes for sessions, carts, feature store entries, realtime counters.
- Table: `Livora_UserStore`
  - PK: `USER#<user_id_or_anon>`
  - SK: `<TYPE>#<id>` where type ∈ {SESSION, CART, ATTR, FEATURE}
  - GSI: `GSI1` on `email` / `phone` if needed
- Item size: aim < 400 KB per item; use S3 references for large blobs.

**Aurora PostgreSQL**
- Purpose: CRM canonical tables (contacts, companies, deals, activities), complex joins and transactions.
- Schema highlights:
  - `contacts(id, user_id, name, email, phone, created_at, source)`
  - `deals(id, contact_id, product_id, stage, value, created_at, closed_at)`
  - `activities(id, deal_id, type, metadata, ts)`

**Transactions:**
- Orders may be duplicated between DynamoDB (checkout session) and Aurora (ledger). Use an ordered write: 
  1) Order created event -> put in Aurora (transactional) -> emit event -> operational store update.

---

## 7. Data Lake & Warehouse
**Flow:** Firehose → S3 (Parquet) → Glue Catalog → Redshift Spectrum/Redshift or BigQuery

**Design:**
- Partition by date and hour. Use compression (snappy) for Parquet.
- Keep raw and curated layers: `raw/events/` and `curated/funnels/`.
- Materialized aggregates: daily/hourly funnels, product_performance, cohort_retention, ltv.

**Example aggregate table:** `product_performance_daily(date, product_id, views, add_to_cart, purchases, revenue)`

**ETL cadence:**
- Streaming: near‑real-time counters updated via Lambda into DynamoDB for live dashboards.
- Batch: nightly Glue jobs to produce heavy aggregates stored in Redshift.

---

## 8. Analytics API & CRM Desktop Integration
**Requirements:** CRM desktop app needs fast, paginated read APIs with RBAC. It should not query Redshift directly.

**Pattern:**
- Build a **Read API** layer (serverless or small ECS service) that exposes precomputed aggregates from Redshift and cached hot results from Redis.
- Embed QuickSight dashboards via AWS embed SDK for heavy visuals or serve JSON endpoints for custom charts.

**Endpoints (examples):**
- `GET /api/v1/analytics/funnel?start=&end=&product_id=&group_by=` → returns funnel step counts and conversion rates.
- `GET /api/v1/contacts/{id}/lifetime` → returns contact summary, orders, last touch, score.

**Caching:**
- Use Redis for 1–5 minute cache; invalidate on key events.

---

## 9. Campaign & Automation Engine
**Core parts:**
- **Segmenter**: runs queries on aggregated tables to produce customer segments (audiences).
- **Orchestrator**: Step Functions / custom state machine to define campaign journeys.
- **Delivery workers**: Lambda/ECS tasks that call Twilio (WhatsApp), SES (email), SNS (SMS), FCM (push).
- **Feedback loop**: delivery webhooks feed back into event stream and CRM activities.

**Automation pattern:**
- Example: cart_abandonment
  1. `add_to_cart` event -> schedule a timer job with EventBridge (30 mins).
  2. If no `purchase`, orchestrator triggers WhatsApp template via Twilio.
  3. Track clicks/open events -> update CRM activity.

**Throttling & Quotas:**
- Global channel quotas per client. Use Redis counters per channel to throttle.

---

## 10. AI / ML Layer
**Use cases:** churn prediction, next‑best offer, product recommendations, lead scoring.

**Architecture:**
- **Feature Store**: DynamoDB/Redis stores realtime features. Batch features stored in S3/warehouse.
- **Training pipeline**: Glue/SageMaker pipelines pull curated datasets from Redshift/S3 to train models.
- **Serving**: Models deployed as endpoints (SageMaker or custom containers on ECS/EKS). Low latency predictions cached in Redis.
- **Feedback & retraining**: continuous loop—prediction results + outcomes appended to training dataset.

**Example process:**
- Input features: recency, frequency, avg_order_value, last_touch_channel, days_since_last_purchase.
- Output: churn_probability, recommended_offer_id.

---

## 11. Observability & Monitoring
**Metrics:** API latency, errors, Kinesis iterator age, DLQ counts, DynamoDB throttling, ETL job durations.

**Tools:** CloudWatch + Prometheus/Grafana, X‑Ray (traces), ELK/Opensearch for logs.

**Alerting:** PagerDuty/SNS for critical issues: consumer lag > X, throttling > Y, error rate > Z.

**Runbooks:**
- DLQ handling procedure
- Kinesis shard resharding guide
- DynamoDB hot partition mitigation
- Redshift vacuum & compression steps

---

## 12. Security & Compliance
- **Auth**: Cognito / OAuth2 with JWT; use short TTLs and refresh tokens.
- **Encryption**: KMS for S3, DynamoDB, Aurora; enforce TLS in transit.
- **IAM**: Least privilege for services; separate roles per environment.
- **Secrets**: Secrets Manager / Vault for API keys and credentials.
- **PII handling**: Tokenize sensitive fields; store PII encrypted in Aurora only when necessary.
- **Audit logs**: Enable CloudTrail / Audit logging for DB and infra changes.

---

## 13. Deployment & IaC
**IaC:** AWS CDK (TypeScript) or Terraform. Structure:
```
infra/cdk-core
infra/cdk-crm
infra/cdk-analytics
infra/cdk-campaigns
```
**Environments:** dev / staging / prod. Use parameterized stacks and secure cross-account deployment.

**CI/CD:** GitHub Actions or CodePipeline
- Build → Unit tests → IaC synth → Deploy to staging → Integration tests → Promote to prod.
- Use Blue/Green or Canary for API updates.

---

## 14. Backups, DR & Retention
- **Data lake**: S3 lifecycle rules (raw: 365 days, curated: 3+ years).
- **DynamoDB**: On‑demand backups & point-in-time recovery.
- **Aurora**: Automated backups + snapshots.
- **Warehouse**: periodic snapshot exports to S3.
- **DR plan**: cross‑region replication for S3 & DynamoDB global tables if client requires.

---

## 15. Testing Strategy
- **Unit tests**: all services
- **Integration tests**: mock Kinesis + localstack for infra tests
- **End‑to‑end tests**: simulate SDK events → check pipeline → check CRM activity.
- **Load testing**: use k6 / Gatling for ingestion spikes.
- **Data quality tests**: Great Expectations jobs for ETL validation.

---

## 16. Operational Playbook (starter checklist)
**Pre‑launch:**
- Configure IAM roles & secrets
- Provision Kinesis shards and Firehose
- Glue Catalog + Redshift cluster
- Set up QuickSight workspaces
- Configure Twilio, SES, SNS credentials

**Go‑live checklist:**
- End‑to‑end smoke test (event -> S3 -> Redshift -> dashboard)
- Campaign test messages to QA numbers
- Permission audit
- Monitoring & alerting baseline

**Post‑launch:**
- Weekly: ETL & model health checks
- Monthly: security audit & cost review

---

## 17. Integration contracts (sample)
**Event Ingestion API (POST /events)**
- Headers: `Authorization: Bearer <token>`, `X-Client-Id`
- Body: single event (as canonical schema) or array of events (max 100)
- Responses: 200 (accepted), 400 (invalid), 429 (rate limit)

**Analytics Read API (GET /analytics/funnel)**
- Query params: `start, end, product_id, group_by`
- Response: counts per funnel step + conversion %

**CRM API (REST)**
- `GET /contacts/{id}` → contact profile
- `POST /deals` → create deal
- `GET /campaigns/{id}/deliveries` → deliveries status

---

## 18. Migration & Onboarding approach for clients
**Phase A: Audit & Mapping**
- Identify existing data sources (shop, ERP, payment gateway) and schema mapping.
- Plan user id mapping & backfill strategy.

**Phase B: Pilot**
- Short pilot (2–4 weeks) with limited traffic and sample dataset.
- Validate events, ETL, dashboards, and automation flows.

**Phase C: Full migration**
- Backfill historical events to S3, re-run ETL.
- Switch production domain and monitor closely for 72 hours.

---

## 19. Developer & Team notes
- Use shared libraries for SDK (JS/TS, Android, iOS) that wrap event formatting and batching.
- Maintain a central schema repo (Glue schema registry + git) and version tags for breaking changes.
- Keep common util library for authentication, retries, HTTP clients.

---

## 20. Deliverables for team (what to hand over)
- `infra/` CDK stacks and README
- `services/` microservices code + tests
- `sdk/` telemetry SDKs for web/mobile
- `docs/` API contract (OpenAPI), runbooks, onboarding plan
- `dashboards/` QuickSight templates and sample reports

---

## 21. Appendices (quick references)
**DynamoDB Single Table keys (example):**
- `PK=USER#auth|123`, `SK=SESSION#sess-1`
- `PK=USER#anon|xyz`, `SK=CART#`

**Sample SQL (funnel)**
```sql
SELECT
  session_id,
  MIN(CASE WHEN event_type='product_view' THEN ts END) as first_view,
  MIN(CASE WHEN event_type='add_to_cart' THEN ts END) as first_add,
  MIN(CASE WHEN event_type='purchase' THEN ts END) as first_purchase
FROM events_parquet
WHERE dt between '2025-10-01' and '2025-10-31'
GROUP BY session_id;
```

**Contact points**: ensure every service writes significant events to the central stream so analytics remain reliable.

---

## Closing
This document is intentionally action‑oriented. Use it as the canonical technical spec: copy infra examples into CDK/Terraform, implement SDKs from the event model, and set up the pipelines in the order suggested (ingest → ops store → lake → warehouse → analytics → automation → AI).

If you want, I can now:
- Add detailed mermaid diagrams into this document, or
- Export this guide as `Livora_Technical_Build_Guide.md` and PDF, or
- Generate starter CDK skeletons for `core`, `crm`, and `analytics` stacks.

Tell me which of the three you want next and I will add it directly into the canvas.

